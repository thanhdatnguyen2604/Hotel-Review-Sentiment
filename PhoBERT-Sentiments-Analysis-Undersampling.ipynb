{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"execution":{"iopub.execute_input":"2022-09-27T14:49:07.071296Z","iopub.status.busy":"2022-09-27T14:49:07.070347Z","iopub.status.idle":"2022-09-27T14:52:21.780112Z","shell.execute_reply":"2022-09-27T14:52:21.778945Z","shell.execute_reply.started":"2022-09-27T14:49:07.071186Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow-text==2.9.0\n","  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting tensorflow<2.10,>=2.9.0\n","  Downloading tensorflow-2.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-text==2.9.0) (0.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.1.0)\n","Collecting absl-py>=1.0.0\n","  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers<2,>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.12)\n","Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.7.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.4.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.19.4)\n","Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.12.1)\n","Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.21.6)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.43.0)\n","Collecting libclang>=13.0.0\n","  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.2.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (59.8.0)\n","Collecting tensorboard<2.10,>=2.9\n","  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (4.3.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (21.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.1.2)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.15.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.6.3)\n","Collecting keras<2.10.0,>=2.9.0rc0\n","  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.3.0)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n","  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.37.1)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.3.7)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.6.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.2.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.28.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.0.9)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.2.7)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (4.12.0)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.26.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2022.6.15.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.1.1)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.2.0)\n","Installing collected packages: libclang, keras, tensorflow-io-gcs-filesystem, tensorflow-estimator, absl-py, tensorboard, tensorflow, tensorflow-text\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.6.0\n","    Uninstalling keras-2.6.0:\n","      Successfully uninstalled keras-2.6.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.6.0\n","    Uninstalling tensorflow-estimator-2.6.0:\n","      Successfully uninstalled tensorflow-estimator-2.6.0\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 0.15.0\n","    Uninstalling absl-py-0.15.0:\n","      Successfully uninstalled absl-py-0.15.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.10.0\n","    Uninstalling tensorboard-2.10.0:\n","      Successfully uninstalled tensorboard-2.10.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.6.4\n","    Uninstalling tensorflow-2.6.4:\n","      Successfully uninstalled tensorflow-2.6.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.9.2 which is incompatible.\n","tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, but you have tensorflow-io-gcs-filesystem 0.27.0 which is incompatible.\n","flax 0.6.0 requires rich~=11.1, but you have rich 12.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed absl-py-1.2.0 keras-2.9.0 libclang-14.0.6 tensorboard-2.9.1 tensorflow-2.9.2 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.27.0 tensorflow-text-2.9.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.11.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.8.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.12.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting underthesea\n","  Downloading underthesea-1.3.4-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.2)\n","Requirement already satisfied: unidecode in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.3.4)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from underthesea) (4.64.0)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.1)\n","Collecting underthesea-core==0.0.4_alpha.10\n","  Downloading underthesea_core-0.0.4_alpha.10-cp37-cp37m-manylinux2010_x86_64.whl (581 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.2/581.2 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-crfsuite>=0.9.6\n","  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from underthesea) (6.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from underthesea) (3.7)\n","Requirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.7/site-packages (from underthesea) (8.0.4)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from underthesea) (2.28.1)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click>=6.0->underthesea) (4.12.0)\n","Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->underthesea) (2021.11.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2022.6.15.2)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2.1.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (1.26.12)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (3.3)\n","Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.21.6)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.7.3)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (4.3.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (3.8.0)\n","Installing collected packages: underthesea-core, python-crfsuite, underthesea\n","Successfully installed python-crfsuite-0.9.8 underthesea-1.3.4 underthesea-core-0.0.4a10\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting py_vncorenlp\n","  Downloading py_vncorenlp-0.1.3.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting pyjnius\n","  Downloading pyjnius-1.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n","\u001b[?25hRequirement already satisfied: six>=1.7.0 in /opt/conda/lib/python3.7/site-packages (from pyjnius->py_vncorenlp) (1.15.0)\n","Building wheels for collected packages: py_vncorenlp\n","  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.3-py3-none-any.whl size=4309 sha256=44aa64eb380f10c69baf8ef31f89bec43751addb7c7e9145d8f18c9a01a28c02\n","  Stored in directory: /root/.cache/pip/wheels/87/be/55/d5930c1d90a09832e9afd57a9e13801e3d16c88f5a19f777ae\n","Successfully built py_vncorenlp\n","Installing collected packages: pyjnius, py_vncorenlp\n","Successfully installed py_vncorenlp-0.1.3 pyjnius-1.4.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting fastBPE\n","  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: fastBPE\n","  Building wheel for fastBPE (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp37-cp37m-linux_x86_64.whl size=746410 sha256=d3bfd8f765b657e0c3ec0fa0e5cd78d478b83ecaeab9f153df46de9ed181b751\n","  Stored in directory: /root/.cache/pip/wheels/bd/d4/0e/0d317a65f77d3f8049fedd8a2ee0519164cf3e6bd77ef886f1\n","Successfully built fastBPE\n","Installing collected packages: fastBPE\n","Successfully installed fastBPE-0.1.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting tokenization\n","  Downloading tokenization-1.0.7-py3-none-any.whl (10 kB)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from tokenization) (2021.11.10)\n","Installing collected packages: tokenization\n","Successfully installed tokenization-1.0.7\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting vncorenlp\n","  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from vncorenlp) (2.28.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (2022.6.15.2)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (2.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (3.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (1.26.12)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=e7b50f68ca7a24580012fa01414277f9f954937eedec2311429f2c399658973b\n","  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting fairseq\n","  Downloading fairseq-0.12.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hCollecting sacrebleu>=1.4.12\n","  Downloading sacrebleu-2.2.1-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.11.0)\n","Collecting hydra-core<1.1,>=1.0.7\n","  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from fairseq) (2021.11.10)\n","Requirement already satisfied: cffi in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.15.0)\n","Collecting bitarray\n","  Downloading bitarray-2.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.4/235.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from fairseq) (0.29.32)\n","Requirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from fairseq) (0.11.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.21.6)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from fairseq) (4.64.0)\n","Collecting omegaconf<2.1\n","  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Collecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.8.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from omegaconf<2.1->fairseq) (4.3.0)\n","Requirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.7/site-packages (from omegaconf<2.1->fairseq) (6.0)\n","Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (2.5.1)\n","Requirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (4.9.1)\n","Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.5)\n","Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi->fairseq) (2.21)\n","Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq) (3.8.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=3bd1222b8cf5957ceae8246cdf50c0bc8b353d700438bf6b5fdbfcb520c50579\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: bitarray, antlr4-python3-runtime, sacrebleu, omegaconf, hydra-core, fairseq\n","Successfully installed antlr4-python3-runtime-4.8 bitarray-2.6.0 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 sacrebleu-2.2.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting demoji\n","  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m490.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: demoji\n","Successfully installed demoji-1.1.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting pyvi\n","  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from pyvi) (1.0.2)\n","Collecting sklearn-crfsuite\n","  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (1.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (3.1.0)\n","Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyvi) (1.21.6)\n","Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->pyvi) (0.8.10)\n","Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n","Requirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->pyvi) (4.64.0)\n","Requirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->pyvi) (0.9.8)\n","Installing collected packages: sklearn-crfsuite, pyvi\n","Successfully installed pyvi-0.1.1 sklearn-crfsuite-0.3.6\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install tensorflow-text==2.9.0\n","!pip install torch\n","!pip install transformers\n","!pip install underthesea\n","!pip install py_vncorenlp\n","!pip install fastBPE\n","!pip install tokenization\n","!pip install vncorenlp\n","!pip install fairseq\n","!pip install demoji\n","!pip install pyvi"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:52:21.782998Z","iopub.status.busy":"2022-09-27T14:52:21.782351Z","iopub.status.idle":"2022-09-27T14:52:30.969516Z","shell.execute_reply":"2022-09-27T14:52:30.968104Z","shell.execute_reply.started":"2022-09-27T14:52:21.782955Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-09-27 14:52:23--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27412575 (26M) [application/octet-stream]\n","Saving to: ‘VnCoreNLP-1.1.1.jar’\n","\n","VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M  --.-KB/s    in 0.1s    \n","\n","2022-09-27 14:52:25 (223 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n","\n","--2022-09-27 14:52:25--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 526544 (514K) [application/octet-stream]\n","Saving to: ‘vi-vocab’\n","\n","vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.03s   \n","\n","2022-09-27 14:52:26 (17.2 MB/s) - ‘vi-vocab’ saved [526544/526544]\n","\n","--2022-09-27 14:52:27--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 128508 (125K) [text/plain]\n","Saving to: ‘wordsegmenter.rdr’\n","\n","wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.02s   \n","\n","2022-09-27 14:52:27 (7.97 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n","\n"]}],"source":["# run 1 lan\n","!mkdir -p vncorenlp/models/wordsegmenter\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","!mv VnCoreNLP-1.1.1.jar vncorenlp/ \n","!mv vi-vocab vncorenlp/models/wordsegmenter/\n","!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:52:30.975233Z","iopub.status.busy":"2022-09-27T14:52:30.974661Z","iopub.status.idle":"2022-09-27T14:53:11.466512Z","shell.execute_reply":"2022-09-27T14:53:11.465084Z","shell.execute_reply.started":"2022-09-27T14:52:30.975199Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-09-27 14:52:31--  https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n","Resolving public.vinai.io (public.vinai.io)... 54.230.31.104, 54.230.31.76, 54.230.31.108, ...\n","Connecting to public.vinai.io (public.vinai.io)|54.230.31.104|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1243308020 (1.2G) [application/x-tar]\n","Saving to: ‘PhoBERT_base_fairseq.tar.gz’\n","\n","PhoBERT_base_fairse 100%[===================>]   1.16G  47.9MB/s    in 23s     \n","\n","2022-09-27 14:52:55 (51.0 MB/s) - ‘PhoBERT_base_fairseq.tar.gz’ saved [1243308020/1243308020]\n","\n","PhoBERT_base_fairseq/\n","PhoBERT_base_fairseq/bpe.codes\n","PhoBERT_base_fairseq/model.pt\n","PhoBERT_base_fairseq/dict.txt\n"]}],"source":["# run 1 lan\n","!wget https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n","!tar -xzvf PhoBERT_base_fairseq.tar.gz"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:11.482712Z","iopub.status.busy":"2022-09-27T14:53:11.482208Z","iopub.status.idle":"2022-09-27T14:53:26.822760Z","shell.execute_reply":"2022-09-27T14:53:26.821525Z","shell.execute_reply.started":"2022-09-27T14:53:11.482654Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-09-27 14:53:12--  https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n","Resolving public.vinai.io (public.vinai.io)... 54.230.31.76, 54.230.31.108, 54.230.31.74, ...\n","Connecting to public.vinai.io (public.vinai.io)|54.230.31.76|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 322405979 (307M) [application/x-tar]\n","Saving to: ‘PhoBERT_base_transformers.tar.gz’\n","\n","PhoBERT_base_transf 100%[===================>] 307.47M  52.3MB/s    in 6.4s    \n","\n","2022-09-27 14:53:19 (47.8 MB/s) - ‘PhoBERT_base_transformers.tar.gz’ saved [322405979/322405979]\n","\n","PhoBERT_base_transformers/\n","PhoBERT_base_transformers/config.json\n","PhoBERT_base_transformers/bpe.codes\n","PhoBERT_base_transformers/model.bin\n","PhoBERT_base_transformers/dict.txt\n"]}],"source":["!wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n","!tar -xzvf PhoBERT_base_transformers.tar.gz"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:26.825752Z","iopub.status.busy":"2022-09-27T14:53:26.824587Z","iopub.status.idle":"2022-09-27T14:53:36.297973Z","shell.execute_reply":"2022-09-27T14:53:36.296054Z","shell.execute_reply.started":"2022-09-27T14:53:26.825688Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","import numpy as np\n","import pandas as pd\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from transformers import AutoModel, AutoTokenizer, AutoConfig, get_linear_schedule_with_warmup, logging\n","from transformers import AutoModelForSequenceClassification, RobertaForSequenceClassification,  BertForSequenceClassification, RobertaConfig, AdamW\n","from scipy.special import softmax\n","import tokenization\n","from tensorflow.keras.utils import to_categorical\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","import torch\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import StratifiedKFold\n","import os\n","import pickle\n","from tqdm.notebook import tqdm\n","from vncorenlp import VnCoreNLP\n","from fairseq.data import Dictionary\n","from fairseq.data.encoders.fastbpe import fastBPE\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch.nn as nn\n","from torch.optim import AdamW\n","from torch.utils.data import Dataset, DataLoader\n","import random\n","from tqdm import tqdm_notebook\n","import argparse\n","from datetime import datetime\n","import regex\n","import demoji\n","from pyvi import ViPosTagger, ViTokenizer\n","import string\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:36.301368Z","iopub.status.busy":"2022-09-27T14:53:36.300102Z","iopub.status.idle":"2022-09-27T14:53:36.592003Z","shell.execute_reply":"2022-09-27T14:53:36.590801Z","shell.execute_reply.started":"2022-09-27T14:53:36.301316Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading codes from ./PhoBERT_base_transformers/bpe.codes ...\n","Read 64000 codes from the codes file.\n"]}],"source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--bpe-codes', \n","    default=\"./PhoBERT_base_transformers/bpe.codes\",\n","    required=False,\n","    type=str,\n","    help='path to fastBPE BPE'\n",")\n","args, unknown = parser.parse_known_args()\n","bpe = fastBPE(args)\n","\n","# Load the dictionary\n","vocab = Dictionary()\n","vocab.add_from_file(\"./PhoBERT_base_transformers/dict.txt\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:36.597131Z","iopub.status.busy":"2022-09-27T14:53:36.596502Z","iopub.status.idle":"2022-09-27T14:53:36.612347Z","shell.execute_reply":"2022-09-27T14:53:36.611145Z","shell.execute_reply.started":"2022-09-27T14:53:36.597092Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:36.617918Z","iopub.status.busy":"2022-09-27T14:53:36.617527Z","iopub.status.idle":"2022-09-27T14:53:36.627810Z","shell.execute_reply":"2022-09-27T14:53:36.626710Z","shell.execute_reply.started":"2022-09-27T14:53:36.617881Z"},"trusted":true},"outputs":[],"source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()    \n","    F1_score = f1_score(pred_flat, labels_flat, average='macro')    \n","    return accuracy_score(pred_flat, labels_flat), F1_score"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:36.633201Z","iopub.status.busy":"2022-09-27T14:53:36.632720Z","iopub.status.idle":"2022-09-27T14:53:43.104334Z","shell.execute_reply":"2022-09-27T14:53:43.103256Z","shell.execute_reply.started":"2022-09-27T14:53:36.633161Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 78936 entries, 0 to 78935\n","Data columns (total 2 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   text_clean  78936 non-null  object\n"," 1   sentiment   78936 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 1.8+ MB\n"]}],"source":["data = pd.read_excel('../input/tripadvisor-data/tripadvisor_dataset.xlsx', index_col=0)\n","data.info()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.109130Z","iopub.status.busy":"2022-09-27T14:53:43.108833Z","iopub.status.idle":"2022-09-27T14:53:43.123452Z","shell.execute_reply":"2022-09-27T14:53:43.122033Z","shell.execute_reply.started":"2022-09-27T14:53:43.109103Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_clean</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hôteldesartsaigon trải_nghiệm tuyệt_vời ghé sà...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>dịch_vụ chuyên_nghiệp tận_tâm nhiên giá hơi th...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>dòng huyền_bí đa sạn lướt hàng sạn đắm_chìm bì...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>thích ngắm mái vòm cửa_sổ tròn hàng ừm thư_thá...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sạn không lắm lối trí ấm_cúng tiệc_đứng nhân_v...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          text_clean  sentiment\n","0  hôteldesartsaigon trải_nghiệm tuyệt_vời ghé sà...          1\n","1  dịch_vụ chuyên_nghiệp tận_tâm nhiên giá hơi th...          1\n","2  dòng huyền_bí đa sạn lướt hàng sạn đắm_chìm bì...          1\n","3  thích ngắm mái vòm cửa_sổ tròn hàng ừm thư_thá...          1\n","4  sạn không lắm lối trí ấm_cúng tiệc_đứng nhân_v...          1"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.126858Z","iopub.status.busy":"2022-09-27T14:53:43.126504Z","iopub.status.idle":"2022-09-27T14:53:43.148850Z","shell.execute_reply":"2022-09-27T14:53:43.147936Z","shell.execute_reply.started":"2022-09-27T14:53:43.126829Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_clean</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>12970</th>\n","      <td>sạn tuyệt_vời tiêu_chuẩn quốc_tế phục_vụ nhân_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>46963</th>\n","      <td>sạn nhân_viên vô thân_thiện sơ_chế cảm trở hàn...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7718</th>\n","      <td>đêm tiêu đêm sạn chuyến dân_tộc ngạc_nhiên nhâ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>61207</th>\n","      <td>ngạc_nhiên trải_nghiệm_sạn núi đình thể mắn gi...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>55941</th>\n","      <td>khám_phá phù_hợp tiêu_chí chuyến nhân_viên bảo...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              text_clean  sentiment\n","12970  sạn tuyệt_vời tiêu_chuẩn quốc_tế phục_vụ nhân_...          1\n","46963  sạn nhân_viên vô thân_thiện sơ_chế cảm trở hàn...          1\n","7718   đêm tiêu đêm sạn chuyến dân_tộc ngạc_nhiên nhâ...          1\n","61207  ngạc_nhiên trải_nghiệm_sạn núi đình thể mắn gi...          1\n","55941  khám_phá phù_hợp tiêu_chí chuyến nhân_viên bảo...          1"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["sentiment_1= data[data['sentiment']==1]\n","sentiment_1= sentiment_1.sample(n=12000, random_state=0)\n","sentiment_1.head(5)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.150751Z","iopub.status.busy":"2022-09-27T14:53:43.150150Z","iopub.status.idle":"2022-09-27T14:53:43.165205Z","shell.execute_reply":"2022-09-27T14:53:43.163984Z","shell.execute_reply.started":"2022-09-27T14:53:43.150693Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_clean</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>64</th>\n","      <td>sạn hơi vô_tư nhân_viên yêu hữu_ích nhiên chuy...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>tiếc lười_biếng phiên_dịch trở lát tiếng việt ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>103</th>\n","      <td>dịch_vụ cập đổi giá phòng phòng tiếp đổi đô ti...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>187</th>\n","      <td>cảm quân đầu_tiên_sạn hơi thất_vọng hình_ảnh q...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>189</th>\n","      <td>hợp sài_gòn_sạn xắn nhộn tây bắc tâm thành_phố...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            text_clean  sentiment\n","64   sạn hơi vô_tư nhân_viên yêu hữu_ích nhiên chuy...          0\n","81   tiếc lười_biếng phiên_dịch trở lát tiếng việt ...          0\n","103  dịch_vụ cập đổi giá phòng phòng tiếp đổi đô ti...          0\n","187  cảm quân đầu_tiên_sạn hơi thất_vọng hình_ảnh q...          0\n","189  hợp sài_gòn_sạn xắn nhộn tây bắc tâm thành_phố...          0"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["sentiment_0= data[data['sentiment']==0]\n","sentiment_0.head(5)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.168476Z","iopub.status.busy":"2022-09-27T14:53:43.168212Z","iopub.status.idle":"2022-09-27T14:53:43.176257Z","shell.execute_reply":"2022-09-27T14:53:43.175150Z","shell.execute_reply.started":"2022-09-27T14:53:43.168451Z"},"trusted":true},"outputs":[],"source":["frames= [sentiment_1, sentiment_0]\n","data= pd.concat(frames)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.178931Z","iopub.status.busy":"2022-09-27T14:53:43.178599Z","iopub.status.idle":"2022-09-27T14:53:43.190291Z","shell.execute_reply":"2022-09-27T14:53:43.189219Z","shell.execute_reply.started":"2022-09-27T14:53:43.178905Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1    12000\n","0    11855\n","Name: sentiment, dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["data['sentiment'].value_counts()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.192184Z","iopub.status.busy":"2022-09-27T14:53:43.191414Z","iopub.status.idle":"2022-09-27T14:53:43.201662Z","shell.execute_reply":"2022-09-27T14:53:43.200649Z","shell.execute_reply.started":"2022-09-27T14:53:43.192151Z"},"trusted":true},"outputs":[],"source":["data= data[['text_clean', 'sentiment']]"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.203703Z","iopub.status.busy":"2022-09-27T14:53:43.203152Z","iopub.status.idle":"2022-09-27T14:53:43.215597Z","shell.execute_reply":"2022-09-27T14:53:43.214585Z","shell.execute_reply.started":"2022-09-27T14:53:43.203666Z"},"trusted":true},"outputs":[{"data":{"text/plain":["text_clean    0\n","sentiment     0\n","dtype: int64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["data.isna().sum()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.217641Z","iopub.status.busy":"2022-09-27T14:53:43.217279Z","iopub.status.idle":"2022-09-27T14:53:43.233584Z","shell.execute_reply":"2022-09-27T14:53:43.232177Z","shell.execute_reply.started":"2022-09-27T14:53:43.217606Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_clean</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sạn tuyệt_vời tiêu_chuẩn quốc_tế phục_vụ nhân_...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sạn nhân_viên vô thân_thiện sơ_chế cảm trở hàn...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>đêm tiêu đêm sạn chuyến dân_tộc ngạc_nhiên nhâ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ngạc_nhiên trải_nghiệm_sạn núi đình thể mắn gi...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>khám_phá phù_hợp tiêu_chí chuyến nhân_viên bảo...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          text_clean  sentiment\n","0  sạn tuyệt_vời tiêu_chuẩn quốc_tế phục_vụ nhân_...          1\n","1  sạn nhân_viên vô thân_thiện sơ_chế cảm trở hàn...          1\n","2  đêm tiêu đêm sạn chuyến dân_tộc ngạc_nhiên nhâ...          1\n","3  ngạc_nhiên trải_nghiệm_sạn núi đình thể mắn gi...          1\n","4  khám_phá phù_hợp tiêu_chí chuyến nhân_viên bảo...          1"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["data.reset_index(inplace=True)\n","data=data[['text_clean', 'sentiment']]\n","data.head()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.236605Z","iopub.status.busy":"2022-09-27T14:53:43.236347Z","iopub.status.idle":"2022-09-27T14:53:43.241635Z","shell.execute_reply":"2022-09-27T14:53:43.240512Z","shell.execute_reply.started":"2022-09-27T14:53:43.236581Z"},"trusted":true},"outputs":[],"source":["X= data['text_clean']\n","y= data['sentiment']"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.244049Z","iopub.status.busy":"2022-09-27T14:53:43.243336Z","iopub.status.idle":"2022-09-27T14:53:43.253667Z","shell.execute_reply":"2022-09-27T14:53:43.252767Z","shell.execute_reply.started":"2022-09-27T14:53:43.244012Z"},"trusted":true},"outputs":[],"source":["train_sents, val_sents, train_labels, val_labels = train_test_split(X, y, test_size=0.2)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.255959Z","iopub.status.busy":"2022-09-27T14:53:43.255120Z","iopub.status.idle":"2022-09-27T14:53:43.265718Z","shell.execute_reply":"2022-09-27T14:53:43.264413Z","shell.execute_reply.started":"2022-09-27T14:53:43.255920Z"},"trusted":true},"outputs":[],"source":["train_labels = np.array(train_labels.tolist())\n","val_labels = np.array(val_labels.tolist())"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:43.267935Z","iopub.status.busy":"2022-09-27T14:53:43.267292Z","iopub.status.idle":"2022-09-27T14:53:51.379850Z","shell.execute_reply":"2022-09-27T14:53:51.378781Z","shell.execute_reply.started":"2022-09-27T14:53:43.267895Z"},"trusted":true},"outputs":[],"source":["MAX_LEN = 100\n","\n","train_ids = []\n","for sent in train_sents:\n","    subwords = '<s> ' + bpe.encode(sent) + ' </s>'\n","    encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n","    train_ids.append(encoded_sent)\n","\n","val_ids = []\n","for sent in val_sents:\n","    subwords = '<s> ' + bpe.encode(sent) + ' </s>'\n","    encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n","    val_ids.append(encoded_sent)\n","    \n","train_ids = pad_sequences(train_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n","val_ids = pad_sequences(val_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:51.382003Z","iopub.status.busy":"2022-09-27T14:53:51.381582Z","iopub.status.idle":"2022-09-27T14:53:52.536029Z","shell.execute_reply":"2022-09-27T14:53:52.534890Z","shell.execute_reply.started":"2022-09-27T14:53:51.381963Z"},"trusted":true},"outputs":[],"source":["train_masks = []\n","for sent in train_ids:\n","    mask = [int(token_id > 0) for token_id in sent]\n","    train_masks.append(mask)\n","\n","val_masks = []\n","for sent in val_ids:\n","    mask = [int(token_id > 0) for token_id in sent]\n","    val_masks.append(mask)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:52.538380Z","iopub.status.busy":"2022-09-27T14:53:52.537947Z","iopub.status.idle":"2022-09-27T14:53:52.707309Z","shell.execute_reply":"2022-09-27T14:53:52.706344Z","shell.execute_reply.started":"2022-09-27T14:53:52.538318Z"},"trusted":true},"outputs":[],"source":["train_inputs = torch.tensor(train_ids)\n","val_inputs = torch.tensor(val_ids)\n","train_labels = torch.tensor(train_labels)\n","val_labels = torch.tensor(val_labels)\n","train_masks = torch.tensor(train_masks)\n","val_masks = torch.tensor(val_masks)\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = SequentialSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n","\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=32)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:53:52.709311Z","iopub.status.busy":"2022-09-27T14:53:52.708922Z","iopub.status.idle":"2022-09-27T14:54:00.707133Z","shell.execute_reply":"2022-09-27T14:54:00.705023Z","shell.execute_reply.started":"2022-09-27T14:53:52.709274Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at ./PhoBERT_base_transformers/model.bin were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'lm_head.decoder.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.dense.bias', 'lm_head.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.embeddings.word_embeddings.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./PhoBERT_base_transformers/model.bin and are newly initialized: ['encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'pooler.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'classifier.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.3.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'classifier.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(64001, 768, padding_idx=0)\n","      (position_embeddings): Embedding(258, 768)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["config = RobertaConfig.from_pretrained(\n","    \"./PhoBERT_base_transformers/config.json\", from_tf=False, num_labels = 2, output_hidden_states=False,\n",")\n","BERT_SA = BertForSequenceClassification.from_pretrained(\n","    \"./PhoBERT_base_transformers/model.bin\",\n","    config=config\n",")\n","BERT_SA.to(device)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:54:00.709315Z","iopub.status.busy":"2022-09-27T14:54:00.708678Z","iopub.status.idle":"2022-09-27T14:54:00.715708Z","shell.execute_reply":"2022-09-27T14:54:00.714785Z","shell.execute_reply.started":"2022-09-27T14:54:00.709275Z"},"trusted":true},"outputs":[],"source":["def save_checkpoint(save_path):\n","        state_dict = {'model_state_dict': BERT_SA.state_dict()}\n","        torch.save(state_dict, save_path)\n","        print(f'Model saved to ==> {save_path}')"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:54:00.717702Z","iopub.status.busy":"2022-09-27T14:54:00.717297Z","iopub.status.idle":"2022-09-27T14:54:00.726914Z","shell.execute_reply":"2022-09-27T14:54:00.725972Z","shell.execute_reply.started":"2022-09-27T14:54:00.717668Z"},"trusted":true},"outputs":[],"source":["epochs = 10\n","best_valid_loss = 999999"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:54:00.728695Z","iopub.status.busy":"2022-09-27T14:54:00.728285Z","iopub.status.idle":"2022-09-27T14:54:00.742627Z","shell.execute_reply":"2022-09-27T14:54:00.741518Z","shell.execute_reply.started":"2022-09-27T14:54:00.728660Z"},"trusted":true},"outputs":[],"source":["from transformers.optimization import AdamW\n","\n","NUM_TRAIN_EPOCHS = 10\n","LEARNING_RATE = 1e-5\n","BATCH_SIZE = 32\n","\n","param_optimizer = list(BERT_SA.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:54:00.749279Z","iopub.status.busy":"2022-09-27T14:54:00.749020Z","iopub.status.idle":"2022-09-27T14:54:00.754897Z","shell.execute_reply":"2022-09-27T14:54:00.753787Z","shell.execute_reply.started":"2022-09-27T14:54:00.749255Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-09-27 14:54:00.750143\n"]}],"source":["t0 = datetime.now()\n","print(t0)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T14:54:00.757299Z","iopub.status.busy":"2022-09-27T14:54:00.756570Z","iopub.status.idle":"2022-09-27T15:27:14.557419Z","shell.execute_reply":"2022-09-27T15:27:14.556558Z","shell.execute_reply.started":"2022-09-27T14:54:00.757198Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["======== Epoch 1 / 10 ========\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca13bd1e9bfe475c831946c75f52d27a","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy (train): 0.8204\n"," F1 score (train): 0.8020\n"," Average training loss: 0.3763\n","Running Validation...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"85b65fa6bf3444419f187a6115113de6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy(val): 0.8865\n"," F1 score(val): 0.8827\n"," Loss (val): 0.2781\n","======== Epoch 2 / 10 ========\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"942dbc1b962b447695f2faefeaad05b5","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy (train): 0.9002\n"," F1 score (train): 0.8971\n"," Average training loss: 0.2544\n","Running Validation...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87e70ebf41cb4cb8ac8f3b21d1152885","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy(val): 0.8954\n"," F1 score(val): 0.8925\n"," Loss (val): 0.2594\n","======== Epoch 3 / 10 ========\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b8a0501cb4f43728cb3e703919b2cea","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy (train): 0.9101\n"," F1 score (train): 0.9073\n"," Average training loss: 0.2341\n","Running Validation...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c09ef096f28342dcbb3a3ff79c10ba1c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy(val): 0.8944\n"," F1 score(val): 0.8916\n"," Loss (val): 0.2544\n","======== Epoch 4 / 10 ========\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff773ea8e15b45c0ae66ff5feb103aa9","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy (train): 0.9132\n"," F1 score (train): 0.9105\n"," Average training loss: 0.2220\n","Running Validation...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03294af7b0d04154aafc92ee0e400e89","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy(val): 0.8931\n"," F1 score(val): 0.8902\n"," Loss (val): 0.2705\n","======== Epoch 5 / 10 ========\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86e102c4188f4d4bbc8eaad027f7848c","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy (train): 0.9181\n"," F1 score (train): 0.9155\n"," Average training loss: 0.2139\n","Running Validation...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fde799c7f15b4fcdb5a873cecbab0c71","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy(val): 0.9000\n"," F1 score(val): 0.8970\n"," Loss (val): 0.2553\n","======== Epoch 6 / 10 ========\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43f4a61479c5492cbaded2a1f8b73435","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy (train): 0.9228\n"," F1 score (train): 0.9206\n"," Average training loss: 0.2040\n","Running Validation...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"140ab35534aa4f108a95c699690849b9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy(val): 0.8896\n"," F1 score(val): 0.8866\n"," Loss (val): 0.2748\n","======== Epoch 7 / 10 ========\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc03ffe051d742068084623f858892b5","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy (train): 0.9280\n"," F1 score (train): 0.9258\n"," Average training loss: 0.1999\n","Running Validation...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f548c7e4e27e42e79b1d0fe101ff17cd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy(val): 0.8950\n"," F1 score(val): 0.8917\n"," Loss (val): 0.2730\n","======== Epoch 8 / 10 ========\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1d4862ddd6645b58e25bad158e69536","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy (train): 0.9332\n"," F1 score (train): 0.9311\n"," Average training loss: 0.1868\n","Running Validation...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2594767baaca43679d8909466c25f816","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy(val): 0.8894\n"," F1 score(val): 0.8865\n"," Loss (val): 0.2862\n","======== Epoch 9 / 10 ========\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b95473b05b9645319e0383ec15ba0faf","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy (train): 0.9329\n"," F1 score (train): 0.9307\n"," Average training loss: 0.1938\n","Running Validation...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f42f3240676045c7bacebc1584fb584a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy(val): 0.8754\n"," F1 score(val): 0.8702\n"," Loss (val): 0.3464\n","======== Epoch 10 / 10 ========\n","Training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2bb8c28ed8d54b1d90306baf04b4d175","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy (train): 0.9388\n"," F1 score (train): 0.9368\n"," Average training loss: 0.1811\n","Running Validation...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"270e0e5953f947bb8aa64004b81107fd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" Accuracy(val): 0.8756\n"," F1 score(val): 0.8705\n"," Loss (val): 0.4009\n","Training complete!\n"]}],"source":["training_stats = []\n","for epoch_i in range(0, NUM_TRAIN_EPOCHS):\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, NUM_TRAIN_EPOCHS))\n","    print('Training...')\n","    \n","    total_loss = 0\n","    BERT_SA.train()\n","    train_accuracy = 0\n","    nb_train_steps = 0\n","    train_f1 = 0\n","    \n","    for step, batch in tqdm_notebook(enumerate(train_dataloader)):\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        BERT_SA.zero_grad()\n","        outputs = BERT_SA(b_input_ids, \n","            token_type_ids=None, \n","            attention_mask=b_input_mask, \n","            labels=b_labels)\n","        loss = outputs[0]\n","        total_loss += loss.item()\n","        \n","        logits = outputs[1].detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        tmp_train_accuracy, tmp_train_f1 = flat_accuracy(logits, label_ids)\n","        train_accuracy += tmp_train_accuracy\n","        train_f1 += tmp_train_f1\n","        nb_train_steps += 1\n","        \n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(BERT_SA.parameters(), 1.0)\n","        optimizer.step()\n","        \n","    avg_train_loss = total_loss / len(train_dataloader)\n","    print(\" Accuracy (train): {0:.4f}\".format(train_accuracy/nb_train_steps))\n","    print(\" F1 score (train): {0:.4f}\".format(train_f1/nb_train_steps))\n","    print(\" Average training loss: {0:.4f}\".format(avg_train_loss))\n","\n","    print(\"Running Validation...\")\n","    BERT_SA.eval()\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    eval_f1 = 0\n","    for batch in tqdm_notebook(val_dataloader):\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        with torch.no_grad():\n","            outputs = BERT_SA(b_input_ids, \n","                            token_type_ids=None, \n","                            labels=b_labels, #add\n","                            attention_mask=b_input_mask)\n","            \n","            tmp_eval_loss, logits = outputs[0], outputs[1]\n","            logits = logits.detach().cpu().numpy()\n","            label_ids = b_labels.to('cpu').numpy()\n","\n","            tmp_eval_accuracy, tmp_eval_f1 = flat_accuracy(logits, label_ids)\n","\n","            eval_accuracy += tmp_eval_accuracy\n","            eval_loss += tmp_eval_loss\n","            eval_f1 += tmp_eval_f1\n","            nb_eval_steps += 1\n","            \n","    print(\" Accuracy(val): {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\" F1 score(val): {0:.4f}\".format(eval_f1/nb_eval_steps))\n","    print(\" Loss (val): {0:.4f}\".format(eval_loss/nb_eval_steps))\n","    \n","    if best_valid_loss > eval_loss:\n","        best_valid_loss = eval_loss\n","        PATH= './model_best_valoss.pt'\n","        torch.save(BERT_SA, PATH)\n","\n","print(\"Training complete!\")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T15:27:14.564016Z","iopub.status.busy":"2022-09-27T15:27:14.561777Z","iopub.status.idle":"2022-09-27T15:27:14.572463Z","shell.execute_reply":"2022-09-27T15:27:14.571389Z","shell.execute_reply.started":"2022-09-27T15:27:14.563976Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0:33:13.815494\n"]}],"source":["t1 = datetime.now()\n","print(t1-t0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Prediction"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T15:27:14.575166Z","iopub.status.busy":"2022-09-27T15:27:14.574480Z","iopub.status.idle":"2022-09-27T15:27:15.066291Z","shell.execute_reply":"2022-09-27T15:27:15.064025Z","shell.execute_reply.started":"2022-09-27T15:27:14.575132Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(64001, 768, padding_idx=0)\n","      (position_embeddings): Embedding(258, 768)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["PATH= './model_best_valoss.pt'\n","model= torch.load(PATH)\n","model.eval()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T15:27:15.068425Z","iopub.status.busy":"2022-09-27T15:27:15.067576Z","iopub.status.idle":"2022-09-27T15:27:29.084994Z","shell.execute_reply":"2022-09-27T15:27:29.084010Z","shell.execute_reply.started":"2022-09-27T15:27:15.068386Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fe827a5ae1c47388928c2c134f9744d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["predictions = []\n","labels = []\n","for batch in tqdm_notebook(val_dataloader):\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        with torch.no_grad():\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            labels=b_labels, #add\n","                            attention_mask=b_input_mask)\n","            \n","            logits = outputs[1]\n","            \n","            logits = logits.detach().cpu().numpy()\n","            label_ids = b_labels.to('cpu').numpy()\n","            \n","            pred_flat = np.argmax(logits, axis=1).flatten()\n","            labels_flat = label_ids.flatten()\n","            \n","            predictions.append(pred_flat)\n","            labels.append(labels_flat)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T15:27:37.993943Z","iopub.status.busy":"2022-09-27T15:27:37.993550Z","iopub.status.idle":"2022-09-27T15:27:38.000496Z","shell.execute_reply":"2022-09-27T15:27:37.999400Z","shell.execute_reply.started":"2022-09-27T15:27:37.993912Z"},"trusted":true},"outputs":[],"source":["# Create an array to return to prediction list\n","prediction = np.array([])\n","\n","for i in predictions:\n","    prediction = np.concatenate([prediction, i])"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T15:27:40.031912Z","iopub.status.busy":"2022-09-27T15:27:40.030761Z","iopub.status.idle":"2022-09-27T15:27:40.038303Z","shell.execute_reply":"2022-09-27T15:27:40.037170Z","shell.execute_reply.started":"2022-09-27T15:27:40.031864Z"},"trusted":true},"outputs":[],"source":["# Create an array to return to true_value list\n","true_value = np.array([])\n","\n","for i in labels:\n","    true_value = np.concatenate([true_value, i])"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T15:27:40.711423Z","iopub.status.busy":"2022-09-27T15:27:40.711032Z","iopub.status.idle":"2022-09-27T15:27:40.726903Z","shell.execute_reply":"2022-09-27T15:27:40.725912Z","shell.execute_reply.started":"2022-09-27T15:27:40.711393Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[2113  176]\n"," [ 331 2151]]\n"]}],"source":["# confusion matrix\n","conf_mat = confusion_matrix(true_value,prediction)\n","print(conf_mat)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T15:27:41.784812Z","iopub.status.busy":"2022-09-27T15:27:41.783823Z","iopub.status.idle":"2022-09-27T15:27:42.033664Z","shell.execute_reply":"2022-09-27T15:27:42.032719Z","shell.execute_reply.started":"2022-09-27T15:27:41.784766Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["from sklearn.metrics import ConfusionMatrixDisplay\n","classes = ['Negative', 'Possitive']\n","disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=classes)\n","disp.plot(cmap=plt.cm.Blues)\n","plt.show()"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-09-27T15:27:42.949653Z","iopub.status.busy":"2022-09-27T15:27:42.949277Z","iopub.status.idle":"2022-09-27T15:27:42.971985Z","shell.execute_reply":"2022-09-27T15:27:42.971032Z","shell.execute_reply.started":"2022-09-27T15:27:42.949622Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.92      0.89      2289\n","         1.0       0.92      0.87      0.89      2482\n","\n","    accuracy                           0.89      4771\n","   macro avg       0.89      0.89      0.89      4771\n","weighted avg       0.90      0.89      0.89      4771\n","\n"]}],"source":["print(classification_report(true_value,prediction))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
